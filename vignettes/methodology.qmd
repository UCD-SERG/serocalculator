---
title: "Introduction to seroincidence estimation"
---

# Methodology

## Estimating incidence

The **incidence rate** of a disease over a **specific time period** is 
the rate at which individuals in a population are acquiring that disease 
during that time period. 

Example: if ten people in a population of 1000 contract typhoid over a one month time period, 
then the incidence rate for that time period is *"10 new cases per 1000 persons per month"*.

---

More mathematically, the incidence rate *at a given time point* is 
the *derivative* (i.e., the current rate of change over time) 
of the expected cumulative count of infections per person at risk, at that time:

$$\frac{d}{dt} \mathbb{E}\left[\frac{C(t)}{n} \mid N(t) =n\right]$$

where $C(t)$ is the cumulative total number of infections in the population of interest,
and $N(t)$ is the number of individuals at risk at time $t$.

---

## Scale of incidence rates

In both definitions, the units for an incidence rate are "# new infections per # persons at risk per time duration"; 
for example, "new infections per 1000 persons per year". 

For convenience, we can rescale the incidence rate to make it easier to understand; 
for example, we might express incidence as 
"# new infections per 1000 persons per year" or "# new infections per 100,000 persons per day", etc.

## Incidence rate from an individual's perspective

From the perspective of an individual in the population, the incidence rate is the probability of becoming infected at that time point, given that you are at risk.

## Notation

We often use the greek letter $\lambda$ ("lambda") to denote the incidence rate.

## Estimating incidence from cross-sectional data

Typically, it is difficult to estimate changes from a single time point. However, we can sometimes make assumptions that allow us to do so. In particular, if we assume that the incidence rate is constant over time, then we can make some progress.

Suppose we measure disease antibody levels $Y$ for a simple cross-sectional random sample of a population. For a given member of the sample, 
let $T$ denote the time since they were last exposed to typhoid. We don't get to observe $T$ - it is a "latent variable". Instead, we only observe $Y$.

## Time since infection and incidence

If we assume the incidence rate is constant, then the probability that our individual was **last** infected $t$ days ago, $p(T=t)$, 
is equal to the probability of being infected at time $t$ 
(i.e., the incidence rate at time $t$, $\lambda$) 
times the probability of not being infected after time $t$, which turns out to be $\exp(-\lambda t)$.

That is:

$$p(T=t) = \lambda \exp(-\lambda t)$$

## Likelihood for observed infection times

If we could observe $T$ for each individual in our sample, we could compute the likelihood of the data:

$$
\begin{aligned}
\mathcal{L}^*(\lambda)
&= \prod_{i=1}^n p(T=t_i)
= \prod_{i=1}^n \lambda \exp(-\lambda t_i)\\
\end{aligned}
$$

Then we could find the value of $\lambda$ that maximizes this likelihood by taking the logarithm of the likelihood, taking the derivative of that "log-likelihood", setting it equal to 0, and solving for $\lambda$.

## Example log-likelihood curves

```{r}
#| fig-cap: "Example log-likelihood curves"
#| label: fig-ex-lik-curves

library(serocalculator)
library(dplyr)
# Import longitudinal antibody parameters from OSF
curves <-
  "https://osf.io/download/rtw5k/" %>%
  load_curve_params() %>%
  filter(iter < 50)

# Import cross-sectional data from OSF and rename required variables:
xs_data <-
  "https://osf.io/download//n6cp3/" %>%
  load_pop_data()

noise <- url("https://osf.io/download//hqy4v/") %>% readRDS()
```

```{r}
#| fig-cap: "Example log(likelihood) curves"
#| label: fig-loglik
lik_HlyE_IgA <- graph.loglik(
  pop_data = xs_data,
  curve_params = curves,
  noise_params = noise,
  antigen_isos = "HlyE_IgA",
  log_x = TRUE
)

lik_HlyE_IgG <- graph.loglik(
  previous_plot = lik_HlyE_IgA,
  pop_data = xs_data,
  curve_params = curves,
  noise_params = noise,
  antigen_isos = "HlyE_IgG",
  log_x = TRUE
)

lik_both <- graph.loglik(
  previous_plot = lik_HlyE_IgG,
  pop_data = xs_data,
  curve_params = curves,
  noise_params = noise,
  antigen_isos = c("HlyE_IgG", "HlyE_IgA"),
  log_x = TRUE
)

print(lik_both)
```

## standard error

The standard error of the estimate is approximately equal to the inverse of the rate of curvature (2nd derivative, aka Hessian) in the log-likelihood function, at the maximum:

more curvature -> likelihood peak is clearer -> smaller standard errors

## The plot thickens

Unfortunately, we don't observe infection times $T$; we only observe antibody levels ${Y}$. So things get a little more complicated.

In short, we are hoping that we can estimate $T$ (time since last infection) from $Y$ (current antibody levels). If we could do that, then we could plug in our estimates $\hat t_i$ into that likelihood above, and estimate $\lambda$ as previously.

We're actually going to do something a little more nuanced; instead of just using one value for $\hat t$, we are going to consider all possible values of $t$ for each individual.

## Likelihood of observed data

The likelihood of our individual's observed data, $P(Y=y)$, can be expressed as an integral over the joint probability of $Y$ and $T$ (using the Law of Total Probability):

$$
\begin{aligned}
p(Y=y) 
&= \int_t p(Y=y,T=t)dt
\end{aligned}
$$

---

Further, we can express the joint probability $p(Y=y,T=t)$ as the product of $p(T=t)$ and 
$p(Y=y|T=t)$ the "antibody response curve after infection". That is:

$$
p(Y=y,T=t) = p(Y=y|T=t)P(T=t)
$$

## Antibody response decay curves

::: {#fig-decay}

![](fig/fig1a-1.svg)

Antibody response decay curves, $p(Y=y|T=t)$, for typhoid

:::

## Putting it all together

Substituting $p(Y=y,T=t) = p(Y=y|T=t)P(T=t)$ into the previous expression for $p(Y=y)$:

$$
\begin{aligned}
p(Y=y)
&= \int_t p(Y=y|T=t)P(T=t) dt
\end{aligned}
$$

## Composing the likelihood {.smaller}

Now, the likelihood of the observed data $\vec{y} = (y_1, y_2, ..., y_n)$ is:

$$
\begin{aligned}
\mathcal{L}(\lambda) 
&= \prod_{i=1}^n p(Y=y_i)
\\&= \prod_{i=1}^n \int_t p(Y=y_i|T=t)p_\lambda(T=t)dt\\
\end{aligned}
$$

If we know $p(Y=y|T=t)$, then we can maximize $\mathcal{L}(\lambda)$ over $\lambda$ to find the "maximum likelihood estimate" (MLE) of $\lambda$, denoted $\hat\lambda$.

## Finding the MLE numerically

The likelihood of $Y$ involves the product of integrals, so the log-likelihood involves the sum of the logs of integrals:

$$
\begin{aligned}
\log \mathcal{L} (\lambda) 
&= \log \prod_{i=1}^n \int_t p(Y=y_i|T=t)p_\lambda(T=t)dt\\
&= \sum_{i=1}^n \log\left\{\int_t p(Y=y_i|T=t)p_\lambda(T=t)dt\right\}\\
\end{aligned}
$$

::: notes

The derivative of this expression doesn't come out cleanly, so we will use a *numerical method* (specifically, a Newton-type algorithm, implemented by `stats::nlm()`) to find the MLE and corresponding standard error.

:::

# Modeling $p(Y=y|T=t)$

## fA simple model for the seroresponse {.smaller}

Now, the big problem becomes modeling $p(Y=y|T=t)$.

The current version of the serocalculator package uses the model proposed in @Teunis_2016 for 
the shape of the seroresponse:

$$
\begin{array}{ll}
\text{Infection/colonization episode} & \text{Waning immunity episode}\\
b^{\prime}(t) = \mu_{0}b(t) - cy(t) & b(t) = 0 \\
y^{\prime}(t) = \mu y(t) & y^{\prime}(t) = -\alpha y(t)^r \\
\end{array}
$$

With baseline antibody concentration $y(0) = y_{0}$ and initial pathogen concentration 
$b(0) = b_{0}$. 

---

The serum antibody response $y(t)$ can be written as

$$
y(t) = y_{+}(t) + y_{-}(t)
$$

where

$$
\begin{align}
y_{+}(t) & = y_{0}\text{e}^{\mu t}[0\le t <t_{1}]\\
y_{-}(t) & = y_{1}\left(1+(r-1)y_{1}^{r-1}\alpha(t-t_{1})\right)^{-\frac{1}{r-1}}[t_{1}\le t < \infty]
\end{align}
$$

---

Since the peak level is $y_{1} = y_{0}\text{e}^{\mu t_{1}}$ 
the growth rate $\mu$ can be written as 
$$\mu = \frac{1}{t_{1}}\log\left(\frac{y_{1}}{y_{0}}\right)$$

---

::: {#fig-response-graph}

```{r}

cur_ai = "HlyE_IgG"
curve1 = 
  curves %>% 
  filter(
    # iter %in% 1:10,
    iter == 5,
         antigen_iso == cur_ai)

library(ggplot2)

curve1 %>% 
serocalculator:::plot_curve_params_one_ab(
  log_y = FALSE
) +
  xlim(0, 100) +
  theme_minimal() +
  geom_vline(
    aes(xintercept = curve1$t1,
        col = "t1")
  ) +
  
  geom_hline(
    aes(yintercept = curve1$y0,
        col = "y0")
  ) +
  
  
  geom_hline(
    aes(yintercept = curve1$y1,
        col = "y1")
  ) +
  # geom_point(
  #   data = curve1,
  #   aes(
  #     x = t1,
  #     y = y1,
  #     col = "(t1,y1)"
  #   )
  # ) + 
  theme(legend.position = "bottom") +
  labs(col = "")

```


:::: notes
The antibody level at $t=0$ is $y_{0}$; 
the rising branch ends at $t = t_{1}$ 
where the peak antibody level $y_{1}$ is reached. 
Any antibody level $y(t) \in (y_{0}, y_{1})$ eventually occurs twice.
::::

An example kinetics curve for `r cur_ai`

:::

---

Antibody decay is different from exponential (log--linear) decay. When the shape parameter $r > 1$, 
log concentrations decrease rapidly after infection has terminated, 
but decay then slows down and 
low antibody concentrations are maintained for a long period. 
When $r$ approaches 1, exponential 
decay is restored.


## Biological noise

When we measure antibody concentrations in a blood sample, we are essentially counting molecules (using biochemistry).

We might miss some of the antibodies (undercount, false negatives) and we also might incorrectly count some other molecules that aren't actually the ones we are looking for (overcount, false positives, cross-reactivity).

We are more concerned about overcount (cross-reactivity) than undercount. For a given antibody, we can do some analytical work beforehand to estimate the distribution of overcounts, and add that to our model $p(Y=y|T=t)$.

## Measurement noise

There are also some other sources of noise in our bioassays; user differences in pipetting technique, random ELISA plate effects, etc. This noise can cause both overcount and undercount. We can also estimate the magnitude of this noise source, and include it in $p(Y=y|T=t)$.

<!-- {{< include methods-continued.qmd >}} -->

---

# References
