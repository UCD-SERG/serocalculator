::: notes
If we could observe $T$, 
then we could estimate $\lambda$
using a typical maximum likelihood approach.
:::

:::: incremental

::::: notes
Starting with the likelihood:
:::::

* $$\Lik^*(\lambda) = \prod_{i=1}^n p(T=t_i) = \prod_{i=1}^n \lambda \exp(-\lambda t_i)$$

::::: notes
Taking the logarithm of the likelihood:
:::::

* $$\llik^*(\lambda) = \logf{\Lik^*(\lambda)} = \sum_{i=1}^n \logf{\lambda} -\lambda t_i$$

::::: notes
Taking the derivative of that log-likelihood to find the score function:
:::::

* $$\llik^{*'}(\lambda) = \sum_{i=1}^n \invf{\lambda} - t_i$$

::::: notes
Setting the score function equal to 0 to find the score equation, 
and solving the score equation for $\lambda$ 
to find the maximum likelihood estimate:
:::::

* $$\hat{\lambda}_{\text{ML}} = \frac{n}{\sum_{i=1}^n t_i} = \frac{1}{\bar{t}}$$

::::

::: notes
The MLE turns out to be the inverse of the mean.
:::
